{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4024cea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import time\n",
    "import tensorflow as tf\n",
    "\n",
    "np.random.seed(13)\n",
    "tf.random.set_seed(13)\n",
    "\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, train_test_split\n",
    "from wordcloud import WordCloud\n",
    "from xml.sax import ContentHandler, parse\n",
    "\n",
    "from nltk import word_tokenize\n",
    "import nltk\n",
    "\n",
    "#nltk.download('punkt')\n",
    "\n",
    "stemmer = SnowballStemmer('english', ignore_stopwords=True)\n",
    "stop = set(stopwords.words('english'))\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set(rc={'figure.figsize':(11.7,8.27)})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87433104",
   "metadata": {},
   "source": [
    "### Class that hadles excel files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99ed386f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "class ExcelHandler(ContentHandler):\n",
    "    def __init__(self):\n",
    "        self.chars = [  ]\n",
    "        self.cells = [  ]\n",
    "        self.rows = [  ]\n",
    "        self.tables = [  ]\n",
    "    def characters(self, content):\n",
    "        self.chars.append(content)\n",
    "    def startElement(self, name, atts):\n",
    "        if name==\"Cell\":\n",
    "            self.chars = [  ]\n",
    "        elif name==\"Row\":\n",
    "            self.cells=[  ]\n",
    "        elif name==\"Table\":\n",
    "            self.rows = [  ]\n",
    "    def endElement(self, name):\n",
    "        if name==\"Cell\":\n",
    "            self.cells.append(''.join(self.chars))\n",
    "        elif name==\"Row\":\n",
    "            self.rows.append(self.cells)\n",
    "        elif name==\"Table\":\n",
    "            self.tables.append(self.rows)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "245ea807",
   "metadata": {},
   "outputs": [],
   "source": [
    "excelHandler = ExcelHandler()\n",
    "parse('data/features.xls', excelHandler)\n",
    "features = pd.DataFrame(excelHandler.tables[0][1:], columns=excelHandler.tables[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea81001",
   "metadata": {},
   "source": [
    "Parse Excel file and create dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39a1d695",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.where(features['Label'] == 'objective', 0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63aab7bf",
   "metadata": {},
   "source": [
    "Create labels: objective = 0, subjective = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef60043",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = []\n",
    "normalized_texts = []\n",
    "\n",
    "for i in range(1, 1001):\n",
    "    if i // 10 == 0:\n",
    "        num = '000' + str(i)\n",
    "    elif i // 100 == 0:\n",
    "        num = '00' + str(i)\n",
    "    elif i // 1000 == 0:\n",
    "        num = '0' + str(i)\n",
    "    else:\n",
    "        num = '1000'\n",
    "    \n",
    "    f = open('data/raw-data/Text' + num + '.txt', 'r', encoding='latin-1')\n",
    "    text = f.read()\n",
    "    \n",
    "    # removes any non-alphabetic characters and tokenizes \n",
    "    # the text from the Natural Language Toolkit (nltk)\n",
    "    \n",
    "    normalized_text = ' '.join([stemmer.stem(w) for w in word_tokenize(text) if (w.isalpha() and w not in stop)])\n",
    "    texts.append(text)\n",
    "    normalized_texts.append(normalized_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42fe7cc1",
   "metadata": {},
   "source": [
    "Read text files and preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7f3008",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.DataFrame({'texts': np.array(texts), 'normalized_texts': np.array(normalized_texts), 'label': y})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8903f6d4",
   "metadata": {},
   "source": [
    "Create dataframe for the texts and their labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a76edee",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_texts = ' '.join(dataframe[dataframe['label'] == 0]['normalized_texts'].tolist())\n",
    "sub_texts = ' '.join(dataframe[dataframe['label'] == 1]['normalized_texts'].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac20ba1c",
   "metadata": {},
   "source": [
    "Create two strings for the preprocessed texts: one for objective and one for subjective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74789879",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(np.array(normalized_texts), y, random_state=13, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1394d616",
   "metadata": {},
   "source": [
    "Splits the data into training and testing sets for use in a machine learning model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39c2ad3",
   "metadata": {},
   "source": [
    "# Decision Tree's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7ee26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b70095",
   "metadata": {},
   "source": [
    "Create an instance of the TfidfVectorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa971fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77bfa915",
   "metadata": {},
   "source": [
    "Fit the vectorizer on the training data and transform the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7507635",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vectorized = vectorizer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c30927b9",
   "metadata": {},
   "source": [
    "Transform the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcddb6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_vectorized = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a38398",
   "metadata": {},
   "source": [
    "Create an instance of the DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c2d91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5284dbdd",
   "metadata": {},
   "source": [
    "Fit the model on the vectorized training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bac1c7c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "classifier.fit(X_train_vectorized, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b46cdc7",
   "metadata": {},
   "source": [
    "Make predictions on the vectorized test data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe43a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test_vectorized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4351ac32",
   "metadata": {},
   "source": [
    "Summary of the predictions made by the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acbbeff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b545931",
   "metadata": {},
   "source": [
    "#### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac5f94e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0fc6de9",
   "metadata": {},
   "source": [
    "#### Accuracy Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2bab2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('accuracy is',accuracy_score(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b515694",
   "metadata": {},
   "source": [
    "# Support Vector Machine's (SVM) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069c1966",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b7324c",
   "metadata": {},
   "source": [
    "Create an instance of the SVC (Support Vector Classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a485402b",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = SVC()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c673d1a",
   "metadata": {},
   "source": [
    "Fit the model on the vectorized training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2ac699",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.fit(X_train_vectorized, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa090cd",
   "metadata": {},
   "source": [
    "Make predictions on the vectorized test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81984b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a498aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ae2392",
   "metadata": {},
   "source": [
    "#### Print the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5675663",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d18145",
   "metadata": {},
   "source": [
    "#### Accuracy Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d36c611",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e5f52e",
   "metadata": {},
   "source": [
    "# K-Nearest Neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1f2e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b8717f",
   "metadata": {},
   "source": [
    "Create an instance of the KNN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774dc0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = KNeighborsClassifier(n_neighbors=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1b4154",
   "metadata": {},
   "source": [
    "Fit the model on the vectorized training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77bce5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.fit(X_train_vectorized, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d1daee",
   "metadata": {},
   "source": [
    "Make predictions on the vectorized test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0276af",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test_vectorized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e15e03",
   "metadata": {},
   "source": [
    "Summary of the predictions made by the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da46f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8220db",
   "metadata": {},
   "source": [
    "#### Print the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ebed768",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d8fe9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Accuracy Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fdeacf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('accuracy is',accuracy_score(y_pred,y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
