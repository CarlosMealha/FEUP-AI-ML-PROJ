{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4024cea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-18 16:18:22.703492: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import time\n",
    "import tensorflow as tf\n",
    "\n",
    "np.random.seed(13)\n",
    "tf.random.set_seed(13)\n",
    "\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, train_test_split\n",
    "from wordcloud import WordCloud\n",
    "from xml.sax import ContentHandler, parse\n",
    "\n",
    "from nltk import word_tokenize\n",
    "import nltk\n",
    "\n",
    "#nltk.download('punkt')\n",
    "\n",
    "stemmer = SnowballStemmer('english', ignore_stopwords=True)\n",
    "stop = set(stopwords.words('english'))\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set(rc={'figure.figsize':(11.7,8.27)})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87433104",
   "metadata": {},
   "source": [
    "### Class that hadles excel files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99ed386f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17 µs, sys: 2 µs, total: 19 µs\n",
      "Wall time: 20.5 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "class ExcelHandler(ContentHandler):\n",
    "    def __init__(self):\n",
    "        self.chars = [  ]\n",
    "        self.cells = [  ]\n",
    "        self.rows = [  ]\n",
    "        self.tables = [  ]\n",
    "    def characters(self, content):\n",
    "        self.chars.append(content)\n",
    "    def startElement(self, name, atts):\n",
    "        if name==\"Cell\":\n",
    "            self.chars = [  ]\n",
    "        elif name==\"Row\":\n",
    "            self.cells=[  ]\n",
    "        elif name==\"Table\":\n",
    "            self.rows = [  ]\n",
    "    def endElement(self, name):\n",
    "        if name==\"Cell\":\n",
    "            self.cells.append(''.join(self.chars))\n",
    "        elif name==\"Row\":\n",
    "            self.rows.append(self.cells)\n",
    "        elif name==\"Table\":\n",
    "            self.tables.append(self.rows)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "245ea807",
   "metadata": {},
   "outputs": [],
   "source": [
    "excelHandler = ExcelHandler()\n",
    "parse('data/features.xls', excelHandler)\n",
    "features = pd.DataFrame(excelHandler.tables[0][1:], columns=excelHandler.tables[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea81001",
   "metadata": {},
   "source": [
    "Parse Excel file and create dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39a1d695",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.where(features['Label'] == 'objective', 0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63aab7bf",
   "metadata": {},
   "source": [
    "Create labels: objective = 0, subjective = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ef60043",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = []\n",
    "normalized_texts = []\n",
    "\n",
    "for i in range(1, 1001):\n",
    "    if i // 10 == 0:\n",
    "        num = '000' + str(i)\n",
    "    elif i // 100 == 0:\n",
    "        num = '00' + str(i)\n",
    "    elif i // 1000 == 0:\n",
    "        num = '0' + str(i)\n",
    "    else:\n",
    "        num = '1000'\n",
    "    \n",
    "    f = open('data/raw-data/Text' + num + '.txt', 'r', encoding='latin-1')\n",
    "    text = f.read()\n",
    "    \n",
    "    # removes any non-alphabetic characters and tokenizes \n",
    "    # the text from the Natural Language Toolkit (nltk)\n",
    "    \n",
    "    normalized_text = ' '.join([stemmer.stem(w) for w in word_tokenize(text) if (w.isalpha() and w not in stop)])\n",
    "    texts.append(text)\n",
    "    normalized_texts.append(normalized_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42fe7cc1",
   "metadata": {},
   "source": [
    "Read text files and preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db7f3008",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.DataFrame({'texts': np.array(texts), 'normalized_texts': np.array(normalized_texts), 'label': y})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8903f6d4",
   "metadata": {},
   "source": [
    "Create dataframe for the texts and their labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a76edee",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_texts = ' '.join(dataframe[dataframe['label'] == 0]['normalized_texts'].tolist())\n",
    "sub_texts = ' '.join(dataframe[dataframe['label'] == 1]['normalized_texts'].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac20ba1c",
   "metadata": {},
   "source": [
    "Create two strings for the preprocessed texts: one for objective and one for subjective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74789879",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(np.array(normalized_texts), y, random_state=13, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1394d616",
   "metadata": {},
   "source": [
    "Splits the data into training and testing sets for use in a machine learning model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33133951",
   "metadata": {},
   "source": [
    "# Decision Tree's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77606215",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de8e62a",
   "metadata": {},
   "source": [
    "Create an instance of the TfidfVectorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a38373",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc91e596",
   "metadata": {},
   "source": [
    "Fit the vectorizer on the training data and transform the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5cde594",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vectorized = vectorizer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0a54cb",
   "metadata": {},
   "source": [
    "Transform the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aea3977",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_vectorized = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dfedcc5",
   "metadata": {},
   "source": [
    "Create an instance of the DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d111912",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f9cd97",
   "metadata": {},
   "source": [
    "Fit the model on the vectorized training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c6d10e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "classifier.fit(X_train_vectorized, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6e3a1d",
   "metadata": {},
   "source": [
    "Make predictions on the vectorized test data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063d6983",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test_vectorized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca88c5e",
   "metadata": {},
   "source": [
    "Summary of the predictions made by the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ef8ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47871770",
   "metadata": {},
   "source": [
    "#### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d8ae46",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32117ea9",
   "metadata": {},
   "source": [
    "#### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03ae1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('accuracy is',accuracy_score(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2252be",
   "metadata": {},
   "source": [
    "# Support Vector Machine's (SVM) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069c1966",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c5c055",
   "metadata": {},
   "source": [
    "Create an instance of the SVC (Support Vector Classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded1d3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = SVC()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3890a7",
   "metadata": {},
   "source": [
    "Fit the model on the vectorized training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e681fb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.fit(X_train_vectorized, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cafc7491",
   "metadata": {},
   "source": [
    "Make predictions on the vectorized test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55076c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba793fb9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aea0700",
   "metadata": {},
   "source": [
    "#### Print the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e0b156",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d9b1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd988d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f495251",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
