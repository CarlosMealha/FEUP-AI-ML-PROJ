{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4024cea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/carlos/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import time\n",
    "import tensorflow as tf\n",
    "\n",
    "np.random.seed(13)\n",
    "tf.random.set_seed(13)\n",
    "\n",
    "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, Conv1D\n",
    "from keras.layers import Bidirectional, GlobalMaxPool1D\n",
    "from keras.models import Model\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from nltk import word_tokenize\n",
    "import nltk\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, train_test_split\n",
    "from wordcloud import WordCloud\n",
    "from xml.sax import ContentHandler, parse\n",
    "from zipfile import ZipFile\n",
    "\n",
    "stemmer = SnowballStemmer('english', ignore_stopwords=True)\n",
    "stop = set(stopwords.words('english'))\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set(rc={'figure.figsize':(11.7,8.27)})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e590a0",
   "metadata": {},
   "source": [
    "### Class that hadles excel files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "99ed386f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 22 µs, total: 22 µs\n",
      "Wall time: 25 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "class ExcelHandler(ContentHandler):\n",
    "    def __init__(self):\n",
    "        self.chars = [  ]\n",
    "        self.cells = [  ]\n",
    "        self.rows = [  ]\n",
    "        self.tables = [  ]\n",
    "    def characters(self, content):\n",
    "        self.chars.append(content)\n",
    "    def startElement(self, name, atts):\n",
    "        if name==\"Cell\":\n",
    "            self.chars = [  ]\n",
    "        elif name==\"Row\":\n",
    "            self.cells=[  ]\n",
    "        elif name==\"Table\":\n",
    "            self.rows = [  ]\n",
    "    def endElement(self, name):\n",
    "        if name==\"Cell\":\n",
    "            self.cells.append(''.join(self.chars))\n",
    "        elif name==\"Row\":\n",
    "            self.rows.append(self.cells)\n",
    "        elif name==\"Table\":\n",
    "            self.tables.append(self.rows)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f711e3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "excelHandler = ExcelHandler()\n",
    "parse('data/features.xls', excelHandler)\n",
    "features = pd.DataFrame(excelHandler.tables[0][1:], columns=excelHandler.tables[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d43e189",
   "metadata": {},
   "source": [
    "Parse Excel file and create dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "26ff2c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.where(features['Label'] == 'objective', 0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653da9ec",
   "metadata": {},
   "source": [
    "Create labels: objective = 0, subjective = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f432d3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = []\n",
    "normalized_texts = []\n",
    "\n",
    "for i in range(1, 1001):\n",
    "    if i // 10 == 0:\n",
    "        number = '000' + str(i)\n",
    "    elif i // 100 == 0:\n",
    "        number = '00' + str(i)\n",
    "    elif i // 1000 == 0:\n",
    "        number = '0' + str(i)\n",
    "    else:\n",
    "        number = '1000'\n",
    "    \n",
    "    f = open('data/raw-data/Text' + number + '.txt', 'r', encoding='latin-1')\n",
    "    text = f.read()\n",
    "    normalized_text = ' '.join([stemmer.stem(w) for w in word_tokenize(text) if (w.isalpha() and w not in stop)])\n",
    "    texts.append(text)\n",
    "    normalized_texts.append(normalized_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddfa0425",
   "metadata": {},
   "source": [
    "Read text files and preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a36871c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame({'texts': np.array(texts), 'normalized_texts': np.array(normalized_texts), 'label': y})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "289752e1",
   "metadata": {},
   "source": [
    "Create dataframe for the texts and their labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7db27eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_texts = ' '.join(data[data['label'] == 0]['normalized_texts'].tolist())\n",
    "sub_texts = ' '.join(data[data['label'] == 1]['normalized_texts'].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a39fe46",
   "metadata": {},
   "source": [
    "Create two strings for the preprocessed texts: one for objective and one for subjective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860e97d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
